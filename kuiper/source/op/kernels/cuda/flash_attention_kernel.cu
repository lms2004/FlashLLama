#include <cuda.h>
#include <cuda_runtime.h>
#include <math.h>
#include <float.h>
#include <stdio.h>
#include <cub/cub.cuh>  // æ·»åŠ  cub å¤´æ–‡ä»¶ç”¨äº BlockReduce
// flash_attention_kernel.cu
#include "flash_attention_kernel.cuh"

// ğŸš€ FlashAttention CUDA kernel - é€‚é… MHA å‚æ•°ç»“æ„
// è¯¥ kernel å®ç°äº† block-wiseã€tile åŒ–çš„é«˜æ•ˆæ³¨æ„åŠ›è®¡ç®—ï¼Œæ˜¾è‘—é™ä½æ˜¾å­˜å ç”¨ï¼Œæå‡é•¿åºåˆ—æ¨ç†é€Ÿåº¦ã€‚
__global__ void flash_attention_forward_kernel(int32_t pos, int32_t seq_len, float* query,
                                               float* score_ptr, float* output, float* key_cache,
                                               float* value_cache, int32_t kv_dim, int32_t kv_mul,
                                               int32_t head_num, int32_t head_size,
                                               int32_t layer_offset) {
    int head = blockIdx.x;
    if (head >= head_num) {
        return;
    }

    int tx = threadIdx.x;
    float scale = 1.f / sqrtf(head_size);
    float* query_head = query + head * head_size;
    float* score_head = score_ptr + head * seq_len;
    int head_offset = (head / kv_mul) * head_size;

    // ğŸ§  å£°æ˜å…±äº«å†…å­˜åŒºï¼šç”¨äºå­˜ Q, K, V ç‰‡æ®µ + ä¸­é—´ç»“æœ S
    extern __shared__ float sram[];
    int tile_size = 32; // ä½¿ç”¨è¾ƒå°çš„ tile size é€‚é… MHA é€»è¾‘
    float* Qi = sram;                           // å½“å‰ tile çš„ Query
    float* Kj = &sram[tile_size * head_size];   // å½“å‰ tile çš„ Key
    float* Vj = &sram[tile_size * head_size * 2]; // å½“å‰ tile çš„ Value
    float* S  = &sram[tile_size * head_size * 3]; // ä¸­é—´ä¹˜ç§¯ç»“æœ

    // ğŸ“¥ å°†å½“å‰ Query åŠ è½½åˆ° shared memory
    for (int x = tx; x < head_size; x += blockDim.x) {
        Qi[x] = query_head[x];
    }
    __syncthreads();

    // ğŸ§® è®¡ç®— attention åˆ†æ•° S = Q Ã— K^Tï¼Œåªå¤„ç†åˆ° pos ä½ç½®
    for (int t = tx; t <= pos; t += blockDim.x) {
        float* key_head = key_cache + layer_offset + t * kv_dim + head_offset;
        
        // è®¡ç®—å½“å‰ token çš„ attention score
        float score = 0.0f;
        #pragma unroll
        for (int i = 0; i < head_size; i += 4) {
            float4 key_head_float4 = *reinterpret_cast<float4*>(key_head + i);
            float4 query_head_float4 = *reinterpret_cast<float4*>(query_head + i);
            score += key_head_float4.x * query_head_float4.x;
            score += key_head_float4.y * query_head_float4.y;
            score += key_head_float4.z * query_head_float4.z;
            score += key_head_float4.w * query_head_float4.w;
        }
        score *= scale;
        score_head[t] = score;
    }
    __syncthreads();

    // ğŸ”¢ ä½¿ç”¨ä¸ MHA ç›¸åŒçš„ softmax å®ç°
    // find max value (for numerical stability)
    float max_val = tx < (pos + 1) ? score_head[tx] : -FLT_MAX;
    for (int i = tx + blockDim.x; i <= pos; i += blockDim.x) {
        if (score_head[i] > max_val) {
            max_val = score_head[i];
        }
    }
    using BlockReduce = cub::BlockReduce<float, 256>;
    __shared__ BlockReduce::TempStorage temp;
    __shared__ float shared_val;
    max_val = BlockReduce(temp).Reduce(max_val, cub::Max());
    if (threadIdx.x == 0) {
        shared_val = max_val;
    }
    __syncthreads();
    max_val = shared_val;

    // è®¡ç®— exp å’Œ sum
    float sum = 0.0f;
    for (int i = tx; i <= pos; i += blockDim.x) {
        score_head[i] = expf(score_head[i] - max_val);
        sum += score_head[i];
    }
    sum = BlockReduce(temp).Sum(sum);
    if (threadIdx.x == 0) {
        shared_val = sum;
    }
    __syncthreads();
    sum = shared_val;

    // å½’ä¸€åŒ–
    for (int i = tx; i <= pos; i += blockDim.x) {
        score_head[i] /= sum;
    }
    __syncthreads();

    // ğŸ¯ è®¡ç®—è¾“å‡ºï¼šweighted sum of values
    float* output_head = output + head * head_size;
    for (int i = tx; i < head_size; i += blockDim.x) {
        float value = 0.0f;
        #pragma unroll
        for (int t = 0; t <= pos; t++) {
            float* value_head = value_cache + layer_offset + t * kv_dim + head_offset;
            float score = score_head[t];
            value += score * value_head[i];
        }
        output_head[i] = value;
    }
}

// C++ å°è£…æ¥å£ï¼Œä¸ mha_kernel_cu ä¿æŒä¸€è‡´çš„å‚æ•°ç»“æ„
void flash_attention_kernel_cu(int32_t pos, int32_t head_num, int32_t layer_index, int32_t seq_len,
                               int32_t kv_dim, int32_t kv_mul, int32_t head_size, 
                               const tensor::Tensor& mha_out,
                               const tensor::Tensor& query_tensor, 
                               const tensor::Tensor& score_tensor,
                               const tensor::Tensor& key_cache_tensor, 
                               const tensor::Tensor& value_cache_tensor,
                               base::DeviceType device_type, kernel::CudaConfig* config) {
    UNUSED(device_type);
    
    // ğŸ§© è®¡ç®—å…±äº«å†…å­˜å¤§å°
    int tile_size = 32;
    size_t sram_size = (3 * tile_size * head_size + tile_size * head_size) * sizeof(float);
    
    // ğŸ“¦ è·å–æ•°æ®æŒ‡é’ˆ
    float* query = const_cast<float*>(query_tensor.ptr<float>());
    float* score = const_cast<float*>(score_tensor.ptr<float>());
    float* output = const_cast<float*>(mha_out.ptr<float>());
    float* key_cache = const_cast<float*>(key_cache_tensor.ptr<float>());
    float* value_cache = const_cast<float*>(value_cache_tensor.ptr<float>());
    
    // ğŸ§® è®¡ç®—å±‚åç§»
    int32_t layer_offset = layer_index * seq_len * kv_dim;
    
    // ğŸš€ å¯åŠ¨ FlashAttention CUDA æ ¸å‡½æ•°
    cudaStream_t stream = config->stream;
    flash_attention_forward_kernel<<<head_num, 256, sram_size, stream>>>(
        pos, seq_len, query, score, output, key_cache, value_cache, 
        kv_dim, kv_mul, head_num, head_size, layer_offset);
}